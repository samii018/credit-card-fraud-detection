{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Capstone Project - Credit Card Fraud Detection ",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "Digital or online banking is advantageous since it enables more customer-centric strategies and gives users instant access to banking services. However, this digital revolution has also opened avenues to banking fraud. Lack of customers’ awareness of online security risks makes them vulnerable to divulging confidential data to criminal groups that can be used to authenticate fraudulent transactions. Though banks are investing significantly to provide digital services to save customers time and money, they are failing to allocate sufficient resources to keep their services secure. Among the many criminal activities occurring in the financial and medical insurance industry, credit card fraud is the most prevalent and taxing owing to the ease and sheer volume at which it occurs. Despite many organizations taking earnest measures to counter and prevent these frauds, they can never be eradicated because criminals ultimately find a loophole or caveat in these steps. The benefits of fraud detection technology still outweigh the risks of heavy investment and inconveniences caused. Thus, countering the fraud activities through continuous up-gradation of data mining and machine learning is one of the main approaches to prevent the losses caused by illegal acts.\n",
        "\n",
        "**Problem statement**\n",
        "\n",
        "The study aims to identify fraudulent credit card transactions on the given data set using data science solutions. We need to develop a model with knowledge of ones that turned out to be fraudulent. This model is then used to identify whether a new transaction is fraudulent or not while minimizing the incorrect fraud classifications.\n",
        "\n",
        "The approach used for solving the problem are:\n",
        "\n",
        "Kaggle has already provided whether data is PCA transformed.\n",
        "\n",
        "**Step -1**: Load the data to understand it. Data understanding is critical since we will select the subset of features to carry out model training, and it includes types of data and its patterns.\n",
        "\n",
        "**Step -2**: Exploratory Data Analysis Study histogram to compare each variable’s data distribution pattern and skewness of the data. Make necessary data adjustments to avoid any problems while we train the model.\n",
        "\n",
        "**Step -3**: Class imbalance Study whether data is highly imbalanced between the fraudulent and non-fraudulent. We have learned four techniques to balance the data using various methods: Under-sampling, oversampling, 2 SMOTE (Synthetic Minority Over Sample Technique), and ADASYN (Adaptive Synthetic). We will use ADASYN techniques to lower the bias introduced by class imbalance and adaptively shift the classification decision boundary towards complex examples.\n",
        "\n",
        "**Step -4**: Data modeling and model selection We will use two classification models (RadomForest and XGBoost) for the current study. For XGBoost, we will identify the number of trees based on the accuracy levels. We will not use KNN since the data set are more than 10K (computation time is increased if data sets are more than 10K). The decision tree gives an interpretation of the flow chart. Hence, it is widely used, but we do not know when to stop building trees and tend to overfit. We will use parameters such as confusion matrix, accuracy, precision, recall, and F-score, threshold dependent. Since data is imbalanced, we will also perform a deep dive into the ROC curve data to identify the threshold value (above the threshold value is fraudulent and below the threshold is not dishonest). We will calculate the F1 score, Precision, and Recall.\n",
        "\n",
        "**Step -5**: Hyperparameter Tunings the model At this time, we will have the best understanding of the type of data we have and the kind of model we were going to build. After model building, our next step will be either hyperparameter tunings (CV or Cross-validation) or grid-search cross-validation or K-Fold or stratified K-Fold, or train validation and test split. This step is essential to improve accuracy, AUC, and lower misclassification error.\n",
        "\n",
        "**Step -6**: Model evaluation Evaluate the model based on AUC -ROC score, through which we will define the threshold value. We will calculate the F1 Score, Precision, and Recall. This will be key for banks to represent the business strategy to bring down the Fraud."
      ],
      "metadata": {
        "id": "Hx6MYHUohhX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Required Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# EDA analysis\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pyplot import show\n",
        "from matplotlib.colors import ListedColormap\n",
        "from plotnine import *\n",
        "import matplotlib.pyplot as Pyplot\n",
        "\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import shapiro\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split,validation_curve, StratifiedShuffleSplit,StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn import over_sampling"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:40.111612Z",
          "iopub.execute_input": "2022-02-20T15:34:40.11192Z",
          "iopub.status.idle": "2022-02-20T15:34:40.134475Z",
          "shell.execute_reply.started": "2022-02-20T15:34:40.111886Z",
          "shell.execute_reply": "2022-02-20T15:34:40.133003Z"
        },
        "trusted": true,
        "id": "pofQRYjwhhYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.warn('foo', DeprecationWarning)\n",
        "import warnings, sklearn.utils\n",
        "warnings.warn('bar', DeprecationWarning)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:40.136192Z",
          "iopub.execute_input": "2022-02-20T15:34:40.1365Z",
          "iopub.status.idle": "2022-02-20T15:34:40.158151Z",
          "shell.execute_reply.started": "2022-02-20T15:34:40.136455Z",
          "shell.execute_reply": "2022-02-20T15:34:40.156848Z"
        },
        "trusted": true,
        "id": "Rlk9bnZyhhYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Will create the seperator for better data visualization among each variables\n",
        "def Line_Separator():\n",
        "    print('*'*50, '\\n')\n",
        "\n",
        "def Line_Separator1():\n",
        "    print('*'*100, '\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:40.159767Z",
          "iopub.execute_input": "2022-02-20T15:34:40.160038Z",
          "iopub.status.idle": "2022-02-20T15:34:40.172682Z",
          "shell.execute_reply.started": "2022-02-20T15:34:40.160008Z",
          "shell.execute_reply": "2022-02-20T15:34:40.171613Z"
        },
        "trusted": true,
        "id": "r1vl78NMhhYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load the data file\n",
        "\n",
        "creditcard=pd.read_csv('../input/credit-card-fraud-detecion/creditcard.csv', index_col=None)\n",
        "\n",
        "creditcard.head(2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:40.174318Z",
          "iopub.execute_input": "2022-02-20T15:34:40.174632Z",
          "iopub.status.idle": "2022-02-20T15:34:43.698762Z",
          "shell.execute_reply.started": "2022-02-20T15:34:40.174597Z",
          "shell.execute_reply": "2022-02-20T15:34:43.697677Z"
        },
        "trusted": true,
        "id": "OWtgsB6lhhYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate number of columns and rows in given dataset\n",
        "\n",
        "Number_of_row = creditcard.shape[0]\n",
        "Number_of_column = creditcard.shape[1]\n",
        "\n",
        "print('Number of rows in creditcard file     :', Number_of_row)\n",
        "print('Number of columns in creditcard file  :', Number_of_column); Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.701533Z",
          "iopub.execute_input": "2022-02-20T15:34:43.701919Z",
          "iopub.status.idle": "2022-02-20T15:34:43.710779Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.701879Z",
          "shell.execute_reply": "2022-02-20T15:34:43.709335Z"
        },
        "trusted": true,
        "id": "6W_V7etshhYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review columns title in given dataset\n",
        "\n",
        "print(\"Columns name in  creditcard file :\\n\",creditcard.columns.values);Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.71321Z",
          "iopub.execute_input": "2022-02-20T15:34:43.713647Z",
          "iopub.status.idle": "2022-02-20T15:34:43.725926Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.713592Z",
          "shell.execute_reply": "2022-02-20T15:34:43.725129Z"
        },
        "trusted": true,
        "id": "Z_m4qK0MhhYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate number of categorical and numerical features\n",
        "\n",
        "def data_features (data):\n",
        "    categorical_features = creditcard.select_dtypes(exclude = [np.number]).columns\n",
        "    numerical_features = creditcard.select_dtypes(include = [np.number]).columns\n",
        "    print(\"Categorical features in  creditcard file :\\n\",categorical_features);Line_Separator1()\n",
        "    print(\"Numerical features in  creditcard file   :\\n\",numerical_features);Line_Separator1()\n",
        "\n",
        "print(data_features(creditcard))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.727205Z",
          "iopub.execute_input": "2022-02-20T15:34:43.727451Z",
          "iopub.status.idle": "2022-02-20T15:34:43.773489Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.727419Z",
          "shell.execute_reply": "2022-02-20T15:34:43.772288Z"
        },
        "trusted": true,
        "id": "1lcuDVb7hhYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the datatypes\n",
        "print(\"Review the Data Format in  creditcard file :\");Line_Separator()\n",
        "print(creditcard.dtypes);Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.774926Z",
          "iopub.execute_input": "2022-02-20T15:34:43.776933Z",
          "iopub.status.idle": "2022-02-20T15:34:43.788112Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.776876Z",
          "shell.execute_reply": "2022-02-20T15:34:43.787133Z"
        },
        "trusted": true,
        "id": "w9Obrd-RhhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify missing value if any\n",
        "\n",
        "print(\"Check if there is any missing value in in  creditcard file :\");Line_Separator()\n",
        "print(round(100*(creditcard.isnull()).sum()/len(creditcard),2).sort_values(ascending=False));Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.789558Z",
          "iopub.execute_input": "2022-02-20T15:34:43.790428Z",
          "iopub.status.idle": "2022-02-20T15:34:43.824856Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.790389Z",
          "shell.execute_reply": "2022-02-20T15:34:43.822692Z"
        },
        "trusted": true,
        "id": "S2Y6tiuzhhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Time variable statistics\");Line_Separator()\n",
        "creditcard['Time'].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.826444Z",
          "iopub.execute_input": "2022-02-20T15:34:43.826693Z",
          "iopub.status.idle": "2022-02-20T15:34:43.847194Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.82666Z",
          "shell.execute_reply": "2022-02-20T15:34:43.846425Z"
        },
        "trusted": true,
        "id": "y0VPsNNfhhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is 48hours, and the values seems to represent the second will convert it to hours - 1hour =3600seconds\n",
        "\n",
        "creditcard['Time'] =creditcard['Time']/3600"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.848876Z",
          "iopub.execute_input": "2022-02-20T15:34:43.849225Z",
          "iopub.status.idle": "2022-02-20T15:34:43.856063Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.849178Z",
          "shell.execute_reply": "2022-02-20T15:34:43.854975Z"
        },
        "trusted": true,
        "id": "rl12_MnihhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment of classes one and zero for visualization\n",
        "\n",
        "def replace_data_to_binary(x,y):\n",
        "    creditcard.Class.replace(x,y, inplace=True)\n",
        "\n",
        "\n",
        "replace_data_to_binary(0, 'Non Fraudulent')\n",
        "replace_data_to_binary(1, 'Fraudulent')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.857752Z",
          "iopub.execute_input": "2022-02-20T15:34:43.85804Z",
          "iopub.status.idle": "2022-02-20T15:34:43.903576Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.858005Z",
          "shell.execute_reply": "2022-02-20T15:34:43.902498Z"
        },
        "trusted": true,
        "id": "hOU51OSfhhYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Readmitted distribution\n",
        "\n",
        "fig = plt.figure(figsize=(9,5))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "total = float(len(creditcard))\n",
        "ax = sns.countplot(x=\"Class\",  data=creditcard)\n",
        "plt.xlabel('Class', fontsize=14)\n",
        "plt.ylabel('Number of observations', fontsize=14)\n",
        "plt.title('Distrinution of Class', fontsize =14)\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x()+p.get_width()/2., height + 3, '{:1.2f}'.format(100*height/total),\n",
        "            ha=\"center\",va='bottom')\n",
        "ax.grid(False)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.show();Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:43.904966Z",
          "iopub.execute_input": "2022-02-20T15:34:43.905338Z",
          "iopub.status.idle": "2022-02-20T15:34:44.412431Z",
          "shell.execute_reply.started": "2022-02-20T15:34:43.905289Z",
          "shell.execute_reply": "2022-02-20T15:34:44.411404Z"
        },
        "trusted": true,
        "id": "KRGfLw59hhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate whether data is balanced or not\n",
        "\n",
        "total_count_combined_calss = creditcard['Class'].value_counts()\n",
        "imbalance= (total_count_combined_calss['Fraudulent']/creditcard['Class'].count()*100)/(total_count_combined_calss['Non Fraudulent']/creditcard['Class'].count()*100)*100\n",
        "print('Imbalance Percentage : ' + str(imbalance));Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:44.416192Z",
          "iopub.execute_input": "2022-02-20T15:34:44.41671Z",
          "iopub.status.idle": "2022-02-20T15:34:44.518399Z",
          "shell.execute_reply.started": "2022-02-20T15:34:44.416669Z",
          "shell.execute_reply": "2022-02-20T15:34:44.517403Z"
        },
        "trusted": true,
        "id": "ZMUgPoQxhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Amount details of  transaction :\");Line_Separator()\n",
        "print(creditcard[creditcard[\"Class\"] == \"Fraudulent\"].Amount.describe());Line_Separator()\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(\"Amount details of non-fraudulent transaction :\");Line_Separator()\n",
        "print(creditcard[creditcard[\"Class\"] == \"Non Fraudulent\"].Amount.describe());Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:44.519544Z",
          "iopub.execute_input": "2022-02-20T15:34:44.519762Z",
          "iopub.status.idle": "2022-02-20T15:34:44.668665Z",
          "shell.execute_reply.started": "2022-02-20T15:34:44.519735Z",
          "shell.execute_reply": "2022-02-20T15:34:44.667712Z"
        },
        "trusted": true,
        "id": "WkLtAi5FhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This statistical analysis, it clearly highlights that the average money transaction for the fraudulent ones is observed more compared to non-fraudulent ones."
      ],
      "metadata": {
        "id": "zhRIaIMchhYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the time vs. amount transaction between fraudulent and non-fraudulent\n",
        "\n",
        "print(\"Evaluate the time vs. amount transaction between fraudulent and non-fraudulent\");Line_Separator1()\n",
        "ax=sns.relplot(x=\"Time\", y=\"Amount\",\n",
        "                 col=\"Class\", hue=\"Class\",\n",
        "                 kind=\"scatter\", data=creditcard)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.show(); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:34:44.670277Z",
          "iopub.execute_input": "2022-02-20T15:34:44.670624Z",
          "iopub.status.idle": "2022-02-20T15:35:01.632191Z",
          "shell.execute_reply.started": "2022-02-20T15:34:44.67058Z",
          "shell.execute_reply": "2022-02-20T15:35:01.631589Z"
        },
        "trusted": true,
        "id": "WxJLGTOwhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few insights on the visualization above reveal the following:\n",
        "\n",
        "1. The plot indicates that the fraud amounts were less than approx 2.2k.\n",
        "2. Fraud pattern indicates that the number of data points is observed between 14 to 20 hours on both days.\n",
        "3. We can see a two-picks pattern in time due tonight.\n"
      ],
      "metadata": {
        "id": "1D0UZuKbhhYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign back to class one and zero for analysis\n",
        "def replace_data_to_binary(x,y):\n",
        "    creditcard.Class.replace(x,y, inplace=True)\n",
        "\n",
        "\n",
        "replace_data_to_binary('Non Fraudulent', 0)\n",
        "replace_data_to_binary ('Fraudulent', 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:01.633311Z",
          "iopub.execute_input": "2022-02-20T15:35:01.634072Z",
          "iopub.status.idle": "2022-02-20T15:35:01.771004Z",
          "shell.execute_reply.started": "2022-02-20T15:35:01.634035Z",
          "shell.execute_reply": "2022-02-20T15:35:01.770127Z"
        },
        "trusted": true,
        "id": "_Wy8D87WhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After reassigning class to zero and one, we will evaluate the data type \");Line_Separator1()\n",
        "creditcard.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:01.772133Z",
          "iopub.execute_input": "2022-02-20T15:35:01.772367Z",
          "iopub.status.idle": "2022-02-20T15:35:01.784681Z",
          "shell.execute_reply.started": "2022-02-20T15:35:01.772319Z",
          "shell.execute_reply": "2022-02-20T15:35:01.7834Z"
        },
        "trusted": true,
        "id": "AZqApJUBhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the correlation between different parameters in the dataset if any\n",
        "\n",
        "creditcard_corr=creditcard.corr()\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "ax=sns.heatmap(creditcard_corr)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.show();Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:01.786063Z",
          "iopub.execute_input": "2022-02-20T15:35:01.786279Z",
          "iopub.status.idle": "2022-02-20T15:35:03.393447Z",
          "shell.execute_reply.started": "2022-02-20T15:35:01.786251Z",
          "shell.execute_reply": "2022-02-20T15:35:03.392427Z"
        },
        "trusted": true,
        "id": "tvDe63xlhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few insights on the visualization above reveal the following:\n",
        "1. V7 and V20 are positively correlated with the amount.\n",
        "2. V2 and V5 are negatively correlated with the amount."
      ],
      "metadata": {
        "id": "Sn_V7YzthhYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the data distributions of each variable\n",
        "\n",
        "print(); Line_Separator1()\n",
        "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V1 to V12\"); Line_Separator1()\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "\n",
        "plt.subplot(431)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V1'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V1'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V1\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(432)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V2'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V2'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V2\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(433)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V3'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V3'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V3\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(434)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V4'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V4'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V4\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(435)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V5'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V5'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V5\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(436)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V6'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V6'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V6\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(437)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V7'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V7'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V7\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(438)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V8'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V8'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V8\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(439)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V9'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V9'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V9\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,10)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V10'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V10'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V10\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,11)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V11'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V11'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V11\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,12)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V12'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V12'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V12\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show(); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:03.39513Z",
          "iopub.execute_input": "2022-02-20T15:35:03.395494Z",
          "iopub.status.idle": "2022-02-20T15:35:18.075793Z",
          "shell.execute_reply.started": "2022-02-20T15:35:03.395447Z",
          "shell.execute_reply": "2022-02-20T15:35:18.074986Z"
        },
        "trusted": true,
        "id": "Rai1sn_phhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the data distributions of each variable\n",
        "\n",
        "print(); Line_Separator1()\n",
        "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V13 to V24\"); Line_Separator1()\n",
        "\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "\n",
        "plt.subplot(431)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V13'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V13'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V13\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(432)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V14'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V14'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V14\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(433)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V15'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V15'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V15\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(434)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V16'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V16'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V16\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(435)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V17'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V17'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V17\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(436)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V18'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V18'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V18\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(437)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V19'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V19'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V19\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(438)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V20'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V20'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V20\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(439)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V21'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V21'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V21\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,10)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V22'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V22'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V22\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,11)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V23'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V23'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V23\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(4,3,12)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V24'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V24'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V24\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show(); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:18.077302Z",
          "iopub.execute_input": "2022-02-20T15:35:18.077856Z",
          "iopub.status.idle": "2022-02-20T15:35:32.660493Z",
          "shell.execute_reply.started": "2022-02-20T15:35:18.077821Z",
          "shell.execute_reply": "2022-02-20T15:35:32.65944Z"
        },
        "trusted": true,
        "id": "W-xZhCTXhhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the data distributions of each variable\n",
        "\n",
        "print(); Line_Separator1()\n",
        "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V25 to V28, Time & Amout\"); Line_Separator1()\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "\n",
        "plt.subplot(431)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V25'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V25'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V25\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(432)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V26'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V26'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V26\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(433)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V27'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V27'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V27\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(434)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V28'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V28'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"V28\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(435)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'Time'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'Time'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"Time\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.subplot(436)\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'Amount'] , color='b',shade=True,label='Non Fraudulent')\n",
        "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'Amount'] , color='orange',shade=True, label='Fraudulent')\n",
        "g.grid(False)\n",
        "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
        "plt.xlabel(\"Amount\", fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show(); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:32.662185Z",
          "iopub.execute_input": "2022-02-20T15:35:32.662547Z",
          "iopub.status.idle": "2022-02-20T15:35:39.726925Z",
          "shell.execute_reply.started": "2022-02-20T15:35:32.6625Z",
          "shell.execute_reply": "2022-02-20T15:35:39.725989Z"
        },
        "trusted": true,
        "id": "b-ZWjQi2hhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate data of Non-Fraudulent and Fraudulent to check the skewness and kurtosis\n",
        "\n",
        "Non_Fraudulent= creditcard[creditcard[\"Class\"] == 0]\n",
        "print (\"Non_Fraudulent:\", Non_Fraudulent.shape); Line_Separator()\n",
        "Fraudulent= creditcard[creditcard[\"Class\"] == 1]\n",
        "print (\"Fraudulent:\", Fraudulent.shape); Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:39.728193Z",
          "iopub.execute_input": "2022-02-20T15:35:39.728548Z",
          "iopub.status.idle": "2022-02-20T15:35:39.775226Z",
          "shell.execute_reply.started": "2022-02-20T15:35:39.728511Z",
          "shell.execute_reply": "2022-02-20T15:35:39.77417Z"
        },
        "trusted": true,
        "id": "orPPqhsuhhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non_Fraudulent = to check the skewness and kurtosis.\n",
        "\n",
        "print (\"Non_Fraudulent = To evaluate Mean, Variance, skewness, and kurtosis:\")\n",
        "print(\"\")\n",
        "a = Non_Fraudulent.mean(axis = 0, skipna = True)\n",
        "b = Non_Fraudulent.var(axis = 0, skipna = True)\n",
        "c = Non_Fraudulent.skew(axis = 0, skipna = True)\n",
        "d = Non_Fraudulent.kurtosis(axis = 0, skipna = True)\n",
        "\n",
        "a.index = b.index\n",
        "a.index = c.index\n",
        "a.index = d.index\n",
        "\n",
        "data_Non_Fraudulent = pd.concat([a, b, c, d] ,axis = 1)\n",
        "data_Non_Fraudulent.columns = [\"Mean\", \"Var\", \"Skewness\", \"kurtosis\"]\n",
        "data_Non_Fraudulent=data_Non_Fraudulent.reset_index().rename(index=str, columns={\"index\": \"Variables\"})\n",
        "print(data_Non_Fraudulent); Line_Separator1()\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Fraudulent = to check the skewness and kurtosis\n",
        "\n",
        "print (\"Fraudulent = To evaluate Mean, Variance, skewness, and kurtosis:\")\n",
        "print(\"\")\n",
        "e = Fraudulent.mean(axis = 0, skipna = True)\n",
        "f = Fraudulent.var(axis = 0, skipna = True)\n",
        "g = Fraudulent.skew(axis = 0, skipna = True)\n",
        "h = Fraudulent.kurtosis(axis = 0, skipna = True)\n",
        "\n",
        "e.index = f.index\n",
        "e.index = g.index\n",
        "e.index = h.index\n",
        "\n",
        "data_Fraudulent = pd.concat([a, b, c, d] ,axis = 1)\n",
        "data_Fraudulent.columns = [\"Mean\", \"Var\", \"Skewness\", \"kurtosis\"]\n",
        "data_Fraudulent=data_Fraudulent.reset_index().rename(index=str, columns={\"index\": \"Variables\"})\n",
        "print(data_Fraudulent); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:39.776508Z",
          "iopub.execute_input": "2022-02-20T15:35:39.776746Z",
          "iopub.status.idle": "2022-02-20T15:35:40.405578Z",
          "shell.execute_reply.started": "2022-02-20T15:35:39.776715Z",
          "shell.execute_reply": "2022-02-20T15:35:40.404493Z"
        },
        "trusted": true,
        "id": "Gb74_c9PhhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Skewness = 0 : normally distributed. ; a zero value means that the tails on both sides of the mean balance out overall,\n",
        "2. Skewness > 0: more weight in the left tail of the distribution.\n",
        "3. Skewness < 0: more weight in the right tail of the distribution.\n",
        "\n",
        "For example, a zero value means that the tails on both sides of the mean balance out overall; this is the case for asymmetric distribution, but it can also be true for an asymmetric distribution where one tail is long and thin, and the other is short but fat.\n",
        "\n",
        "**Note:** we will look into this if we require any power transformation to the data. However, they are PCA transformed (not an original one)"
      ],
      "metadata": {
        "id": "mVTRddRihhYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-Fraudulent: Evaluate the number of positive skewness variables\n",
        "\n",
        "print('Non Fraudulent - Positive skewness:')\n",
        "left_skewness_Non_Fraudulent= data_Non_Fraudulent[data_Non_Fraudulent.Skewness >0]\n",
        "print(left_skewness_Non_Fraudulent['Variables'].unique());Line_Separator()\n",
        "\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# Fraudulent : Evaluate the number of positive skewness variables\n",
        "\n",
        "print('Fraudulent - Positive skewness:')\n",
        "left_skewness_Fraudulent = data_Fraudulent[data_Fraudulent.Skewness >0]\n",
        "print(left_skewness_Fraudulent['Variables'].unique());Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.406815Z",
          "iopub.execute_input": "2022-02-20T15:35:40.407146Z",
          "iopub.status.idle": "2022-02-20T15:35:40.417909Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.407113Z",
          "shell.execute_reply": "2022-02-20T15:35:40.41698Z"
        },
        "trusted": true,
        "id": "laR890afhhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Skew:** Mean > median"
      ],
      "metadata": {
        "id": "PG7Dp8HshhYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-Fraudulent: Evaluate the number of negative skewness variables\n",
        "print('Non Fraudulent - Negative skewness:')\n",
        "right_skewness_Non_Fraudulent= data_Non_Fraudulent[data_Non_Fraudulent.Skewness <0]\n",
        "print(right_skewness_Non_Fraudulent['Variables'].unique());Line_Separator()\n",
        "\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# Fraudulent: Evaluate the number of negative skewness variables\n",
        "print('Fraudulent - Negative skewness:')\n",
        "right_skewness_Fraudulent = data_Fraudulent[data_Fraudulent.Skewness <0]\n",
        "print(right_skewness_Fraudulent['Variables'].unique());Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.419231Z",
          "iopub.execute_input": "2022-02-20T15:35:40.419758Z",
          "iopub.status.idle": "2022-02-20T15:35:40.440648Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.419721Z",
          "shell.execute_reply": "2022-02-20T15:35:40.439479Z"
        },
        "trusted": true,
        "id": "nTvtw5pzhhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Negative Skew:** Median > mean\n",
        "2. **Zero Skew:** Mean = median (normal distribution)"
      ],
      "metadata": {
        "id": "UONGOeIuhhYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will drop the time column\n",
        "\n",
        "creditcard = creditcard.drop(['Time'],axis=1)\n",
        "creditcard.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.44171Z",
          "iopub.execute_input": "2022-02-20T15:35:40.442091Z",
          "iopub.status.idle": "2022-02-20T15:35:40.506547Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.441901Z",
          "shell.execute_reply": "2022-02-20T15:35:40.505427Z"
        },
        "trusted": true,
        "id": "AY7ztU16hhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "creditcard['Amount'] = StandardScaler().fit_transform(creditcard['Amount'].values.reshape(-1,1))\n",
        "#creditcard['Time'] = StandardScaler().fit_transform(creditcard['Time'].values.reshape(-1,1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.507843Z",
          "iopub.execute_input": "2022-02-20T15:35:40.508103Z",
          "iopub.status.idle": "2022-02-20T15:35:40.522273Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.50807Z",
          "shell.execute_reply": "2022-02-20T15:35:40.521266Z"
        },
        "trusted": true,
        "id": "imaD7ld4hhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y\n",
        "\n",
        "X = creditcard.drop('Class',axis=1)\n",
        "y = creditcard['Class']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.523816Z",
          "iopub.execute_input": "2022-02-20T15:35:40.524072Z",
          "iopub.status.idle": "2022-02-20T15:35:40.564023Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.524041Z",
          "shell.execute_reply": "2022-02-20T15:35:40.56306Z"
        },
        "trusted": true,
        "id": "IVV0KTVdhhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the X dataset\n",
        "\n",
        "X.head(2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.565679Z",
          "iopub.execute_input": "2022-02-20T15:35:40.566396Z",
          "iopub.status.idle": "2022-02-20T15:35:40.595815Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.566326Z",
          "shell.execute_reply": "2022-02-20T15:35:40.594445Z"
        },
        "trusted": true,
        "id": "uXGCO4b9hhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the data shape\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.597318Z",
          "iopub.execute_input": "2022-02-20T15:35:40.597787Z",
          "iopub.status.idle": "2022-02-20T15:35:40.610935Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.597733Z",
          "shell.execute_reply": "2022-02-20T15:35:40.609801Z"
        },
        "trusted": true,
        "id": "6mTRVqVzhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test with 70-30 division\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, train_size=0.7,  random_state=0)\n",
        "X_train.shape,X_test.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.61218Z",
          "iopub.execute_input": "2022-02-20T15:35:40.612616Z",
          "iopub.status.idle": "2022-02-20T15:35:40.760675Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.612579Z",
          "shell.execute_reply": "2022-02-20T15:35:40.759958Z"
        },
        "trusted": true,
        "id": "SA7STF9ChhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skewness observed in the distribution hence will use power transformation by 'yeo-johnson' method\n",
        "\n",
        "creditcard_pt= preprocessing.PowerTransformer(method='yeo-johnson', copy=True)\n",
        "creditcard_pt.fit(X_train)\n",
        "\n",
        "X_train_pt = creditcard_pt.transform(X_train)\n",
        "X_test_pt = creditcard_pt.transform(X_test)\n",
        "\n",
        "y_train_pt = y_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:40.761798Z",
          "iopub.execute_input": "2022-02-20T15:35:40.762166Z",
          "iopub.status.idle": "2022-02-20T15:35:49.659302Z",
          "shell.execute_reply.started": "2022-02-20T15:35:40.762135Z",
          "shell.execute_reply": "2022-02-20T15:35:49.658424Z"
        },
        "trusted": true,
        "id": "qLvT_QeHhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the x_train and x_test\n",
        "\n",
        "X_train = X_train_pt\n",
        "X_test = X_test_pt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:49.660514Z",
          "iopub.execute_input": "2022-02-20T15:35:49.660765Z",
          "iopub.status.idle": "2022-02-20T15:35:49.66542Z",
          "shell.execute_reply.started": "2022-02-20T15:35:49.660734Z",
          "shell.execute_reply": "2022-02-20T15:35:49.664512Z"
        },
        "trusted": true,
        "id": "vofkfXZ-hhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance data Method used ADASYN oversampling on the minority class\n",
        "\n",
        "X_ada, y_ada = over_sampling.ADASYN(sampling_strategy='minority', random_state=42).fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_ada))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:49.666901Z",
          "iopub.execute_input": "2022-02-20T15:35:49.667626Z",
          "iopub.status.idle": "2022-02-20T15:35:54.523534Z",
          "shell.execute_reply.started": "2022-02-20T15:35:49.667579Z",
          "shell.execute_reply": "2022-02-20T15:35:54.522748Z"
        },
        "trusted": true,
        "id": "91rgQti4hhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataset after balancing it\n",
        "\n",
        "print(X_ada.shape)\n",
        "print(y_ada.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.524497Z",
          "iopub.execute_input": "2022-02-20T15:35:54.525022Z",
          "iopub.status.idle": "2022-02-20T15:35:54.529764Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.524976Z",
          "shell.execute_reply": "2022-02-20T15:35:54.529116Z"
        },
        "trusted": true,
        "id": "WV39QEpNhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute unique data in y_ada\n",
        "\n",
        "y_ada.unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.530889Z",
          "iopub.execute_input": "2022-02-20T15:35:54.531602Z",
          "iopub.status.idle": "2022-02-20T15:35:54.548772Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.531558Z",
          "shell.execute_reply": "2022-02-20T15:35:54.548128Z"
        },
        "trusted": true,
        "id": "l5r57SaAhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate whether the dataset is balanced at what percentage level\n",
        "\n",
        "total_count_combined_calss = y_ada.value_counts()\n",
        "imbalance= (total_count_combined_calss[1]/y_ada.count()*100)/(total_count_combined_calss[0]/y_ada.count()*100)*100\n",
        "print('Balance Percentage after ADASYN : ' + str(imbalance));Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.55014Z",
          "iopub.execute_input": "2022-02-20T15:35:54.55101Z",
          "iopub.status.idle": "2022-02-20T15:35:54.564783Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.55096Z",
          "shell.execute_reply": "2022-02-20T15:35:54.563165Z"
        },
        "trusted": true,
        "id": "MEEpW8GnhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the sum of y_ada, y_train and y_test\n",
        "\n",
        "print(np.sum(y_ada))\n",
        "print(np.sum(y_train))\n",
        "print(np.sum(y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.565997Z",
          "iopub.execute_input": "2022-02-20T15:35:54.567189Z",
          "iopub.status.idle": "2022-02-20T15:35:54.578809Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.567149Z",
          "shell.execute_reply": "2022-02-20T15:35:54.577909Z"
        },
        "trusted": true,
        "id": "JMAQaGWrhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename X_ada and y_ada\n",
        "\n",
        "X_train = X_ada\n",
        "y_train = y_ada"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.580073Z",
          "iopub.execute_input": "2022-02-20T15:35:54.580298Z",
          "iopub.status.idle": "2022-02-20T15:35:54.587899Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.58027Z",
          "shell.execute_reply": "2022-02-20T15:35:54.58702Z"
        },
        "trusted": true,
        "id": "k_fJYQhjhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the shape of the training and test dataset after balancing it\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.596038Z",
          "iopub.execute_input": "2022-02-20T15:35:54.596409Z",
          "iopub.status.idle": "2022-02-20T15:35:54.602338Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.596366Z",
          "shell.execute_reply": "2022-02-20T15:35:54.601428Z"
        },
        "trusted": true,
        "id": "TIIl9m4AhhYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Base Model**"
      ],
      "metadata": {
        "id": "O6RuIbxphhYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Model for evaluation\n",
        "\n",
        "b_m=[]\n",
        "\n",
        "for i in range (y_test.shape[0]):\n",
        "    b_m.append(y_test.mode()[0])\n",
        "\n",
        "len(b_m)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:35:54.603801Z",
          "iopub.execute_input": "2022-02-20T15:35:54.60423Z",
          "iopub.status.idle": "2022-02-20T15:36:45.406102Z",
          "shell.execute_reply.started": "2022-02-20T15:35:54.604198Z",
          "shell.execute_reply": "2022-02-20T15:36:45.405302Z"
        },
        "trusted": true,
        "id": "KaLMXACZhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=pd.Series(b_m)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:36:45.40745Z",
          "iopub.execute_input": "2022-02-20T15:36:45.408108Z",
          "iopub.status.idle": "2022-02-20T15:36:45.466706Z",
          "shell.execute_reply.started": "2022-02-20T15:36:45.408057Z",
          "shell.execute_reply": "2022-02-20T15:36:45.465639Z"
        },
        "trusted": true,
        "id": "y52uA36vhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy (Base Model):', accuracy_score(y_test, y_pred)*100);Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:36:45.468328Z",
          "iopub.execute_input": "2022-02-20T15:36:45.468678Z",
          "iopub.status.idle": "2022-02-20T15:36:45.489746Z",
          "shell.execute_reply.started": "2022-02-20T15:36:45.468635Z",
          "shell.execute_reply": "2022-02-20T15:36:45.488639Z"
        },
        "trusted": true,
        "id": "THvzbrqNhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN Model**\n",
        "\n",
        "1. The KNN model is used when the data points presented are less as the computation time is very high, and it was advised not to use KNN in this capstone.\n",
        "2. However, we have tried it, and it takes more than 8hrs, but there is no certain output; hence we will not be using this model."
      ],
      "metadata": {
        "id": "H_-M1YcJhhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To find the K neighbour value\n",
        "\n",
        "    neighbors = np.arange(1,11)\n",
        "    train_accuracy = np.empty(len(neighbors))\n",
        "    test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "    for i, k in enumerate(neighbors):\n",
        "      knn = KNeighborsClassifier(n_neighbors=k)\n",
        "      knn.fit(X_train, y_train)\n",
        "      train_accuracy[i] = knn.score(X_train, y_train)\n",
        "      test_accuracy[i] = knn.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "jpIphyyBhhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Generate plot\n",
        "    fig = plt.figure(figsize=(8,4))\n",
        "    fig.set_facecolor(\"#F3F3F3\")\n",
        "    plt.title('k-NN: Varying Number of Neighbors', fontsize =12)\n",
        "    plt.plot(neighbors, test_accuracy, label = 'Accuracy on training set')\n",
        "    plt.plot(neighbors, train_accuracy, label = 'Accuracy on testing set')\n",
        "    plt.legend(loc = \"best\", prop = {\"size\" : 14})\n",
        "    plt.xlabel('Number of Neighbors', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "klcKE2gIhhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    There is another approach to identify the k number is\n",
        "\n",
        "    mean error - (mean error zero or lower will be the k)\n",
        "    error = []\n",
        "\n",
        "    Calculating error for K values between 1 and 40 for i in range(1, 40):\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=i) knn.fit(X_train, y_train) pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))\n",
        "    fig = plt.figure(figsize=(8,4))\n",
        "    fig.set_facecolor(\"#F3F3F3\")\n",
        "    plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
        "    plt.title('Error Rate K Value', fontsize=12) plt.xlabel('K Value', fontsize=12) plt.ylabel('Mean Error', fontsize=12)\n",
        "    plt.legend(loc = \"best\", prop = {\"size\" : 12})\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "imIDg62ZhhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We will try to obtain results of all five models under consideration without any optimization and checkout it's performance\n",
        "2. We will first try the Logistic regression model and Xgboost with different values and no optimization to check its performance\n",
        "3. We will use logistic regression with stratified K-fold cross-validation\n",
        "4. Function to plot the validation curve to obtain the right C value for the logistic regression model"
      ],
      "metadata": {
        "id": "4V_2CEXnhhYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_val_curve(train_scores, val_scores, param_range, plt_title):\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    val_scores_mean = np.mean(val_scores, axis=1)\n",
        "    val_scores_std = np.std(val_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(14,6))\n",
        "\n",
        "    plt.title(plt_title)\n",
        "    plt.xlabel(\"$C-Regularization parameter$\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "\n",
        "    lw = 2\n",
        "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
        "                 color=\"darkorange\", lw=lw)\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                     color=\"darkorange\", lw=lw)\n",
        "\n",
        "    plt.semilogx(param_range, val_scores_mean, label=\"Cross-validation score\",\n",
        "                 color=\"navy\", lw=lw)\n",
        "\n",
        "    plt.fill_between(param_range, val_scores_mean - val_scores_std,\n",
        "                     val_scores_mean + val_scores_std, alpha=0.2,\n",
        "                     color=\"navy\", lw=lw)\n",
        "    plt.legend(loc=\"best\")\n",
        "\n",
        "# Number of folds selected for cross-validation is 10\n",
        "\n",
        "K = 10\n",
        "stratified_cv = StratifiedShuffleSplit(n_splits = K, random_state = 0)\n",
        "\n",
        "lgreg = LogisticRegression(penalty='l1', solver='liblinear',random_state=0, n_jobs=-1, max_iter=1000).fit(X_train, y_train)\n",
        "param_C_range = [1e-9, 1e-5, 1e-3, 1e-2, 1e-1, 1.0,10,100]\n",
        "train_scores, val_scores = validation_curve(estimator=lgreg,\n",
        "                                            X=X_train,\n",
        "                                            y=y_train,\n",
        "                                            param_name='C',\n",
        "                                            param_range=param_C_range,\n",
        "                                            cv=stratified_cv,\n",
        "                                            n_jobs=-1,\n",
        "                                            scoring='f1')\n",
        "plot_val_curve(train_scores, val_scores, param_C_range, plt_title='L1 Regularization Parameter Sweep')\n",
        "plt.xscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:36:45.491558Z",
          "iopub.execute_input": "2022-02-20T15:36:45.492253Z",
          "iopub.status.idle": "2022-02-20T15:39:51.917162Z",
          "shell.execute_reply.started": "2022-02-20T15:36:45.492211Z",
          "shell.execute_reply": "2022-02-20T15:39:51.915877Z"
        },
        "trusted": true,
        "id": "-RXmoBkLhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C value which can be used shall be = 0.01 selected from the graph above\n",
        "# Predict class label and probability for the validation data set\n",
        "\n",
        "lgreg = LogisticRegression(penalty='l1', C=0.01,solver='liblinear',random_state=0, n_jobs=-1, max_iter=1000).fit(X_train, y_train)\n",
        "y_pred = lgreg.predict(X_test)\n",
        "y_prob = lgreg.predict_proba(X_test)\n",
        "\n",
        "\n",
        "# Compute classification metrics\n",
        "\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "precision = metrics.precision_score(y_test, y_pred)\n",
        "recall = metrics.recall_score(y_test, y_pred)\n",
        "f1 = metrics.f1_score(y_test, y_pred)\n",
        "logloss = metrics.log_loss(y_test, y_pred)\n",
        "\n",
        "# Compute precision, recall, and AUPRC for different levels of thresholds\n",
        "\n",
        "precisions, recalls, thresholds = metrics.precision_recall_curve(y_test.ravel(), y_prob[:, 1].ravel(), pos_label=1)\n",
        "prc_auc = metrics.average_precision_score(y_test, y_prob[:,1], average='weighted')\n",
        "\n",
        "print('Test accuracy: %.3f' % (accuracy))\n",
        "print('\\nTest Precision: %.3f' % (precision))\n",
        "print('\\nTest Recall: %.3f' % (recall))\n",
        "print('\\nTest LogLoss: %.3f' % (logloss))\n",
        "print('\\nTest AUPRC: %.3f' % (prc_auc))\n",
        "\n",
        "\n",
        "fpr,tpr,thresholds = roc_curve(y_test,y_pred)\n",
        "auc_score = roc_auc_score(y_test,y_pred)\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('LR_1 Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:39:51.919978Z",
          "iopub.execute_input": "2022-02-20T15:39:51.920374Z",
          "iopub.status.idle": "2022-02-20T15:39:59.18439Z",
          "shell.execute_reply.started": "2022-02-20T15:39:51.920293Z",
          "shell.execute_reply": "2022-02-20T15:39:59.183459Z"
        },
        "trusted": true,
        "id": "QWKh5DP9hhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy seems to be 90.6%, which is not so good, and the area under the curve value seems to be good."
      ],
      "metadata": {
        "id": "3tMppRd8hhYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Confusion Matrix\n",
        "\n",
        "classes = ['Not Fraudulent', 'Fraudulent']\n",
        "LR_conf_matrix_1 = confusion_matrix(y_test,y_pred)\n",
        "fig = plt.figure(figsize=(9,5))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "ax= sns.heatmap(LR_conf_matrix_1,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=classes,\n",
        "                yticklabels=classes,\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"LR_conf_matrix_1\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:39:59.185857Z",
          "iopub.execute_input": "2022-02-20T15:39:59.186169Z",
          "iopub.status.idle": "2022-02-20T15:39:59.49294Z",
          "shell.execute_reply.started": "2022-02-20T15:39:59.186125Z",
          "shell.execute_reply": "2022-02-20T15:39:59.492269Z"
        },
        "trusted": true,
        "id": "e1i8HyGqhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Above confusion matrix represents Logistic regression under L1 regularization and C=0.01\n",
        "2.  We will use stratified k fold validation on the XGBoost algorithm next\n",
        "3.  Perform cross-validation using stratified k fold method on the X_train & y_train"
      ],
      "metadata": {
        "id": "iwk9-pdShhYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "X_train_p = X_train_pt\n",
        "y_train_p = y_train_pt\n",
        "skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
        "\n",
        "print(\"XGBOOST Classifier: --------------------------\")\n",
        "cv_score_mean=0\n",
        "for n_estimators in [100,50]:\n",
        "    for learning_rate in [0.2,0.6]:\n",
        "        for subsample in [0.3, 0.6, 0.9]:\n",
        "            print(\"n_estimators=\",n_estimators,\"learning_rate=\",learning_rate, \"subsample=\",subsample)\n",
        "            for train_index, test_index in skf.split(X_train_p, y_train_p):\n",
        "                print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "                X_train_cv, X_test_cv = X_train_p[train_index], X_train_p[test_index]\n",
        "                y_train_cv, y_test_cv = y_train_p.iloc[train_index], y_train_p.iloc[test_index]\n",
        "\n",
        "                ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)\n",
        "                X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)\n",
        "\n",
        "                xgboost_classifier= XGBClassifier(n_estimators=n_estimators,\n",
        "                                                learning_rate=learning_rate,\n",
        "                                                subsample=subsample, n_jobs=-1,\n",
        "                                                eval_metric='logloss',\n",
        "                                                use_label_encoder=False)\n",
        "                xgboost_classifier.fit(X_ros_cv, y_ros_cv)\n",
        "\n",
        "                y_test_pred= xgboost_classifier.predict_proba(X_test_cv)\n",
        "                cv_score= metrics.roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])\n",
        "                cv_score_mean=cv_score_mean+cv_score\n",
        "            print(\"Cross Val ROC-AUC Score=\", cv_score_mean/3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T15:39:59.494551Z",
          "iopub.execute_input": "2022-02-20T15:39:59.49543Z",
          "iopub.status.idle": "2022-02-20T16:10:17.435668Z",
          "shell.execute_reply.started": "2022-02-20T15:39:59.495383Z",
          "shell.execute_reply": "2022-02-20T16:10:17.434138Z"
        },
        "trusted": true,
        "id": "rj5H554BhhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The results shown above suggest we use n_estimators= 100, learning_rate= 0.2 and subsample= 0.3 to obtain highest area under the curve\n",
        "\n",
        "2. Similarly optimization was performed on other three models as well to check its performance, and parameters were selected based on it"
      ],
      "metadata": {
        "id": "7pPOdJRRhhYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the best tree in XGB\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "tree_range = range(2, 100, 5)\n",
        "score1=[]\n",
        "score2=[]\n",
        "for tree in tree_range:\n",
        "    xgb=XGBClassifier(n_estimators=tree,\n",
        "                      eval_metric='mlogloss',\n",
        "                      use_label_encoder=False)\n",
        "    xgb.fit(X_train,y_train)\n",
        "    score1.append(xgb.score(X_train,y_train))\n",
        "    score2.append(xgb.score(X_test,y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T16:10:17.43766Z",
          "iopub.execute_input": "2022-02-20T16:10:17.43793Z",
          "iopub.status.idle": "2022-02-20T16:35:17.486005Z",
          "shell.execute_reply.started": "2022-02-20T16:10:17.437899Z",
          "shell.execute_reply": "2022-02-20T16:35:17.485178Z"
        },
        "trusted": true,
        "id": "bliBqa47hhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate plot for - XGB to obtain the optimum value of trees to be used\n",
        "\n",
        "%matplotlib inline\n",
        "fig = plt.figure(figsize=(8,4))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.plot(tree_range,score1,label= 'Accuracy on training set')\n",
        "plt.plot(tree_range,score2,label= 'Accuracy on testing set')\n",
        "plt.title('XGboost: Number of trees Vs Accuracy', fontsize =12)\n",
        "plt.xlabel('Value of number of trees in XGboost', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.grid(b=None)\n",
        "plt.legend(loc = \"best\",\n",
        "               prop = {\"size\" : 12})\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T16:35:17.490919Z",
          "iopub.execute_input": "2022-02-20T16:35:17.491511Z",
          "iopub.status.idle": "2022-02-20T16:35:17.711257Z",
          "shell.execute_reply.started": "2022-02-20T16:35:17.491463Z",
          "shell.execute_reply": "2022-02-20T16:35:17.710391Z"
        },
        "trusted": true,
        "id": "Xz1ksgkKhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the optimized parameters for\n",
        "\n",
        "xgb=XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train,y_train)\n",
        "print('Accuracy of XGB n=100 on the testing dataset is :{:.4f}'.format(xgb.score(X_test,y_test)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T16:35:17.712775Z",
          "iopub.execute_input": "2022-02-20T16:35:17.713046Z",
          "iopub.status.idle": "2022-02-20T16:37:42.398378Z",
          "shell.execute_reply.started": "2022-02-20T16:35:17.713012Z",
          "shell.execute_reply": "2022-02-20T16:37:42.397507Z"
        },
        "trusted": true,
        "id": "pRdWGiyPhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing various models\n",
        "\n",
        "model_summary = []\n",
        "ML_models = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T16:37:42.400244Z",
          "iopub.execute_input": "2022-02-20T16:37:42.400775Z",
          "iopub.status.idle": "2022-02-20T16:37:42.407087Z",
          "shell.execute_reply.started": "2022-02-20T16:37:42.400735Z",
          "shell.execute_reply": "2022-02-20T16:37:42.405267Z"
        },
        "trusted": true,
        "id": "C7UEJ8wvhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# ML_models = {}\n",
        "\n",
        "model_index = ['LR','RF','NN', 'GRB', 'DT','KN', 'XGB']\n",
        "model_sklearn = [LogisticRegression(penalty = 'l2', C = 1, random_state=0),\n",
        "                 RandomForestClassifier(n_jobs=3, min_samples_split = 20, min_samples_leaf = 5, random_state=0),\n",
        "                 MLPClassifier([100]*5,early_stopping=True,learning_rate='adaptive',random_state=0),\n",
        "                 GradientBoostingClassifier(n_estimators = 50, max_depth = 2, random_state = 0),\n",
        "                 DecisionTreeClassifier(random_state=42, max_depth=6),\n",
        "                 KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
        "                 XGBClassifier(n_estimators=100,learning_rate=0.2,subsample=0.3, n_jobs=-1,\n",
        "                              eval_metric='mlogloss',use_label_encoder=False)]\n",
        "\n",
        "# model_summary = []\n",
        "\n",
        "for name,model in zip(model_index,model_sklearn):\n",
        "    ML_models[name] = model.fit(X_train,y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    model_summary.append([name,f1_score(y_test,preds,average='weighted'),accuracy_score(y_test,preds),\n",
        "                          roc_auc_score(y_test,model.predict_proba(X_test)[:,1]), precision_score(y_test,preds, average='weighted'),\n",
        "                         recall_score(y_test,preds, average='weighted')])\n",
        "\n",
        "\n",
        "print(ML_models)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T16:37:42.409086Z",
          "iopub.execute_input": "2022-02-20T16:37:42.409439Z",
          "iopub.status.idle": "2022-02-20T17:08:10.069289Z",
          "shell.execute_reply.started": "2022-02-20T16:37:42.409389Z",
          "shell.execute_reply": "2022-02-20T17:08:10.06837Z"
        },
        "trusted": true,
        "id": "6B13W8w9hhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the model evaluation parameters\n",
        "\n",
        "model_summary = pd.DataFrame(model_summary,columns=['Name','F1_score','Accuracy', 'AUC_ROC', 'Precision', 'Recall'])\n",
        "model_summary = model_summary.reset_index()\n",
        "display(model_summary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T17:08:10.071123Z",
          "iopub.execute_input": "2022-02-20T17:08:10.07202Z",
          "iopub.status.idle": "2022-02-20T17:08:10.091718Z",
          "shell.execute_reply.started": "2022-02-20T17:08:10.071969Z",
          "shell.execute_reply": "2022-02-20T17:08:10.090754Z"
        },
        "trusted": true,
        "id": "p9_TTrjRhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting all the evaluation parameters of all the models and comparing them to each other\n",
        "\n",
        "plt.rcParams['figure.figsize']=(14,10)\n",
        "plt.subplot(231)\n",
        "g=sns.barplot(data=model_summary, x=\"Name\", y=\"F1_score\")\n",
        "plt.title('ML Model Vs Respective model- F1 Score')\n",
        "\n",
        "plt.subplot(232)\n",
        "g=sns.barplot(data=model_summary, x=\"Name\", y=\"Accuracy\")\n",
        "plt.title('ML Model Vs Respective model- Accuracy')\n",
        "\n",
        "plt.subplot(233)\n",
        "g=sns.barplot(data=model_summary, x=\"Name\", y=\"Precision\")\n",
        "plt.title('ML Model Vs Respective model- Precision')\n",
        "\n",
        "plt.subplot(234)\n",
        "g=sns.barplot(data=model_summary, x=\"Name\", y=\"Recall\")\n",
        "plt.title('ML Model Vs Respective model- Recall')\n",
        "\n",
        "plt.subplot(235)\n",
        "g=sns.barplot(data=model_summary, x=\"Name\", y=\"AUC_ROC\")\n",
        "plt.title('ML Model Vs Respective model- AUC_ROC')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T17:08:10.09323Z",
          "iopub.execute_input": "2022-02-20T17:08:10.093991Z",
          "iopub.status.idle": "2022-02-20T17:08:10.812551Z",
          "shell.execute_reply.started": "2022-02-20T17:08:10.093934Z",
          "shell.execute_reply": "2022-02-20T17:08:10.811434Z"
        },
        "trusted": true,
        "id": "by3jG5J2hhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying the validity of our different models\n",
        "\n",
        "# LR Model\n",
        "\n",
        "ML_test = ML_models['LR'].predict(X_test)\n",
        "ML_train = ML_models['LR'].predict(X_train)\n",
        "LR_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"LR model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(LR_Model_Residuals).value_counts())\n",
        "\n",
        "# RF Model\n",
        "ML_test = ML_models['RF'].predict(X_test)\n",
        "ML_train = ML_models['RF'].predict(X_train)\n",
        "RF_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"RF model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(RF_Model_Residuals).value_counts()); Line_Separator()\n",
        "\n",
        "\n",
        "# NN Model\n",
        "ML_test = ML_models['NN'].predict(X_test)\n",
        "ML_train = ML_models['NN'].predict(X_train)\n",
        "NN_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print (\"NN model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(NN_Model_Residuals).value_counts()); Line_Separator()\n",
        "\n",
        "\n",
        "# GRB Model\n",
        "ML_test = ML_models['GRB'].predict(X_test)\n",
        "ML_train = ML_models['GRB'].predict(X_train)\n",
        "NN_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"GRB model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(NN_Model_Residuals).value_counts()); Line_Separator()\n",
        "\n",
        "\n",
        "# DT Model\n",
        "ML_test = ML_models['DT'].predict(X_test)\n",
        "ML_train = ML_models['DT'].predict(X_train)\n",
        "DT_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"DT model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(DT_Model_Residuals).value_counts()); Line_Separator()\n",
        "\n",
        "\n",
        "# KN Model\n",
        "ML_test = ML_models['KN'].predict(X_test)\n",
        "ML_train = ML_models['KN'].predict(X_train)\n",
        "KN_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"KN model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(KN_Model_Residuals).value_counts()); Line_Separator()\n",
        "\n",
        "# XGB Model\n",
        "ML_test = ML_models['XGB'].predict(X_test)\n",
        "ML_train = ML_models['XGB'].predict(X_train)\n",
        "XGB_Model_Residuals = y_train == ML_train\n",
        "\n",
        "print(); Line_Separator()\n",
        "print (\"XGB model :- Number of values correctly predicted:\"); Line_Separator()\n",
        "print(pd.Series(XGB_Model_Residuals).value_counts()); Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T17:08:10.814174Z",
          "iopub.execute_input": "2022-02-20T17:08:10.814523Z",
          "iopub.status.idle": "2022-02-20T17:44:35.602245Z",
          "shell.execute_reply.started": "2022-02-20T17:08:10.814466Z",
          "shell.execute_reply": "2022-02-20T17:44:35.601419Z"
        },
        "trusted": true,
        "id": "_Wcp_2PWhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for LR, RF, NN, GRB, DT, KN, XGB models\n",
        "\n",
        "# LR\n",
        "LR_conf_matrix = confusion_matrix(y_test,ML_models['LR'].predict(X_test))\n",
        "\n",
        "# RF\n",
        "RF_conf_matrix = confusion_matrix(y_test,ML_models['RF'].predict(X_test))\n",
        "\n",
        "# NN\n",
        "NN_conf_matrix = confusion_matrix(y_test,ML_models['NN'].predict(X_test))\n",
        "\n",
        "# GRB\n",
        "GRB_conf_matrix = confusion_matrix(y_test,ML_models['GRB'].predict(X_test))\n",
        "\n",
        "# DT\n",
        "DT_conf_matrix = confusion_matrix(y_test,ML_models['DT'].predict(X_test))\n",
        "\n",
        "# KN\n",
        "KN_conf_matrix = confusion_matrix(y_test,ML_models['KN'].predict(X_test))\n",
        "\n",
        "# XGB\n",
        "XGB_conf_matrix = confusion_matrix(y_test,ML_models['XGB'].predict(X_test))\n",
        "\n",
        "fig = plt.figure(figsize=(15,18))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.subplot(431)\n",
        "ax= sns.heatmap(LR_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"LR_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(432)\n",
        "ax= sns.heatmap(RF_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"RF_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(433)\n",
        "ax= sns.heatmap(NN_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"NN_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(434)\n",
        "ax= sns.heatmap(GRB_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"GRB_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(435)\n",
        "ax= sns.heatmap(DT_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"DT_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(436)\n",
        "ax= sns.heatmap(KN_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"KN_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(437)\n",
        "ax= sns.heatmap(XGB_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"XGB_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T17:44:35.60546Z",
          "iopub.execute_input": "2022-02-20T17:44:35.605848Z",
          "iopub.status.idle": "2022-02-20T17:53:10.250617Z",
          "shell.execute_reply.started": "2022-02-20T17:44:35.605807Z",
          "shell.execute_reply": "2022-02-20T17:53:10.249527Z"
        },
        "trusted": true,
        "id": "7hbPGKKfhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "\n",
        "target_names = [\"Not Fraudulent\",\"Fraudulent\"]\n",
        "\n",
        "# LR Model\n",
        "print(); Line_Separator()\n",
        "print (\"                LR Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"LR\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# RF Model\n",
        "print (\"                RF Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"RF\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# NN Model\n",
        "print (\"                NN Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"NN\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# GRB Model\n",
        "print (\"                GRB Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"GRB\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# GRB Model\n",
        "print (\"                DT Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"DT\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# KN Model\n",
        "print (\"                KN Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"KN\"].predict(X_test))); Line_Separator()\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------\n",
        "# XGB Model\n",
        "print (\"                XGB Model - Classification Report\"); Line_Separator()\n",
        "print(classification_report(y_test, ML_models[\"XGB\"].predict(X_test))); Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T17:53:10.252439Z",
          "iopub.execute_input": "2022-02-20T17:53:10.252695Z",
          "iopub.status.idle": "2022-02-20T18:01:42.747496Z",
          "shell.execute_reply.started": "2022-02-20T17:53:10.252663Z",
          "shell.execute_reply": "2022-02-20T18:01:42.746506Z"
        },
        "trusted": true,
        "id": "MWq9HSiwhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create speficity, sensitivity, FPR, positive predictive value and Negative predictive value\n",
        "\n",
        "# LR model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['LR'].predict(X_test)).ravel()\n",
        "\n",
        "print(\"            LR Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('false postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "# RF model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['RF'].predict(X_test)).ravel()\n",
        "\n",
        "print(\"            RF Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "# NN model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['NN'].predict(X_test)).ravel()\n",
        "\n",
        "\n",
        "print(\"            NN Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# GRB model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['GRB'].predict(X_test)).ravel()\n",
        "\n",
        "\n",
        "print(\"            GRB Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# DT model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['DT'].predict(X_test)).ravel()\n",
        "\n",
        "\n",
        "print(\"            DT Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# KN model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['KN'].predict(X_test)).ravel()\n",
        "\n",
        "\n",
        "print(\"            KN Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# DT model\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test,ML_models['XGB'].predict(X_test)).ravel()\n",
        "\n",
        "\n",
        "print(\"            XGB Model:\")\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', tp / (tp+fn))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',tn /(tn+fp))\n",
        "\n",
        "# Calculate false postive rate - predicting churn when customer does not have churned\n",
        "print('False postive rate        : ',fp/(tn+fp))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', tp / (tp+fp))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',tn / (tn+ fn)); Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:01:42.749125Z",
          "iopub.execute_input": "2022-02-20T18:01:42.749391Z",
          "iopub.status.idle": "2022-02-20T18:10:15.046758Z",
          "shell.execute_reply.started": "2022-02-20T18:01:42.749361Z",
          "shell.execute_reply": "2022-02-20T18:10:15.045725Z"
        },
        "trusted": true,
        "id": "teB0DvVPhhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC - Curves for all the models\n",
        "fig = plt.figure(figsize=(15,22))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "\n",
        "\n",
        "# LR Model\n",
        "plt.subplot(431)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['LR'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['LR'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('LR Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# RF Model\n",
        "plt.subplot(432)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['RF'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['RF'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('RF Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# NN Model\n",
        "plt.subplot(433)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['NN'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['NN'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('NN Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# GRB Model\n",
        "plt.subplot(434)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['GRB'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['GRB'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('GRB Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# DT Model\n",
        "plt.subplot(435)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['DT'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['DT'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('DT Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# KN Model\n",
        "plt.subplot(436)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['KN'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['KN'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.4f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('KN Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------------------------\n",
        "# XGB Model\n",
        "plt.subplot(437)\n",
        "fpr,tpr,thresholds = roc_curve(y_test,ML_models['XGB'].predict_proba(X_test)[:,1])\n",
        "auc_score = roc_auc_score(y_test,ML_models['XGB'].predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr, linestyle = \"dotted\", color = \"royalblue\",linewidth = 2, label='ROC curve (area = %0.5f)' % auc_score )\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('XGB Model: ROC Curve', fontsize =12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.plot([0,1],[0,1],linestyle = \"dashed\",\n",
        "             color = \"orangered\",linewidth = 1.5)\n",
        "plt.fill_between(fpr,tpr,alpha = .4)\n",
        "plt.fill_between([0,1],[0,1],color = \"y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:10:15.049033Z",
          "iopub.execute_input": "2022-02-20T18:10:15.049393Z",
          "iopub.status.idle": "2022-02-20T18:27:15.409298Z",
          "shell.execute_reply.started": "2022-02-20T18:10:15.049326Z",
          "shell.execute_reply": "2022-02-20T18:27:15.408291Z"
        },
        "trusted": true,
        "id": "7OdeoXEShhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision recall curves for all the models\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# LR_Model\n",
        "\n",
        "fig = plt.figure(figsize=(15,22))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.subplot(431)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['LR'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['LR'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'LR Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_LR Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_LR Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# RF_Model\n",
        "\n",
        "plt.subplot(432)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['RF'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['RF'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'RF Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_RF Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_RF Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# NN_Model\n",
        "\n",
        "plt.subplot(433)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['NN'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['NN'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'NN Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_NN Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_NN Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# GRB_Model\n",
        "\n",
        "plt.subplot(434)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['GRB'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['GRB'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'GRB Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_GRB Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_GRB Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# DT_Model\n",
        "\n",
        "plt.subplot(435)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['DT'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['DT'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'DT Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_DT Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_DT Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# KN_Model\n",
        "\n",
        "plt.subplot(436)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['KN'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "            label = (\"avg_pcn : \" +\n",
        "                     str(np.around(average_precision_score(y_test,ML_models['KN'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'KN Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_KN Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_KN Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "# XGB_Model\n",
        "\n",
        "plt.subplot(437)\n",
        "\n",
        "recall,precision,thresholds = precision_recall_curve(y_test,ML_models['XGB'].predict_proba(X_test)[:,1])\n",
        "plt.plot(recall,precision,linewidth = 1.5,\n",
        "             label = (\"avg_pcn : \" +\n",
        "                      str(np.around(average_precision_score(y_test,ML_models['XGB'].predict(X_test)),5))))\n",
        "plt.plot([0,1],[0,0],linestyle = \"dashed\")\n",
        "plt.fill_between(recall,precision,alpha = .2)\n",
        "plt.legend(loc = 'best',\n",
        "               prop = {\"size\" : 14})\n",
        "plt.grid(True,alpha = .15)\n",
        "plt.title( 'XGB Model: precision_recall_curve', fontsize =12)\n",
        "plt.xlabel(\"Recall_XGB Model\",fontsize =12)\n",
        "plt.ylabel(\"Precision_XGB Model\",fontsize =12)\n",
        "plt.xlim([0.25,1])\n",
        "plt.yticks(np.arange(0,1,.3))\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:27:15.411309Z",
          "iopub.execute_input": "2022-02-20T18:27:15.411599Z",
          "iopub.status.idle": "2022-02-20T18:44:20.839393Z",
          "shell.execute_reply.started": "2022-02-20T18:27:15.411564Z",
          "shell.execute_reply": "2022-02-20T18:44:20.838191Z"
        },
        "trusted": true,
        "id": "59M2-vE4hhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert df with label\n",
        "\n",
        "df= pd.DataFrame(X_train)\n",
        "df_X_train=df.rename(columns={ 0:'V1', 1:'V2', 2:'V3', 3: 'V4', 4: 'V5', 5: 'V6', 6: 'V7', 7: 'V8',\n",
        "                              8: 'V9', 9: 'V10', 10: 'V11', 11: 'V12', 12: 'V13', 13: 'V14', 14: 'V15',15: 'V16',\n",
        "                              16:'V17', 17: 'V18', 18: 'V19', 19: 'V20', 20: 'V21', 21: 'V22',22: 'V23', 23: 'V24',\n",
        "                              24 :'V25', 25: 'V26', 26: 'V27', 27: 'V28', 28:'Amount'})\n",
        "df_X_train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:44:20.841507Z",
          "iopub.execute_input": "2022-02-20T18:44:20.841918Z",
          "iopub.status.idle": "2022-02-20T18:44:21.111401Z",
          "shell.execute_reply.started": "2022-02-20T18:44:20.841866Z",
          "shell.execute_reply": "2022-02-20T18:44:21.110385Z"
        },
        "trusted": true,
        "id": "rg9EkYeWhhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logreg = LogisticRegression(penalty = 'l2', C = 1, random_state=0).fit(X_train, y_train)\n",
        "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
        "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
        "creditcard_features = [x for i,x in enumerate(df_X_train.columns) if i!=8]\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
        "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
        "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
        "plt.xticks(range(creditcard.shape[1]), creditcard_features, rotation=90)\n",
        "plt.hlines(0, 0, creditcard.shape[1])\n",
        "plt.ylim(-5, 5)\n",
        "plt.grid(b=None)\n",
        "plt.xlabel(\"Features\",fontsize=12)\n",
        "plt.ylabel(\"Coefficient magnitude\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.savefig('log_coef')\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NWKDAEHZhhYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variables important\n",
        "# Model - RF\n",
        "\n",
        "importances = ML_models['RF'].feature_importances_\n",
        "\n",
        "# make importance relative to the max importance\n",
        "feature_importance = 100.0 * (importances / importances.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "feature_names = list(df_X_train.columns.values)\n",
        "feature_names_sort = [feature_names[indice] for indice in sorted_idx]\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "# plot the result\n",
        "fig = plt.figure(figsize=(9,8))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, feature_names_sort)\n",
        "plt.title('RF Model: Relative Feature Importance', fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:44:21.11307Z",
          "iopub.execute_input": "2022-02-20T18:44:21.113377Z",
          "iopub.status.idle": "2022-02-20T18:44:21.505941Z",
          "shell.execute_reply.started": "2022-02-20T18:44:21.113327Z",
          "shell.execute_reply": "2022-02-20T18:44:21.504877Z"
        },
        "trusted": true,
        "id": "WSP1nSvvhhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variables important\n",
        "# Model - GRB\n",
        "\n",
        "importances = ML_models['GRB'].feature_importances_\n",
        "\n",
        "# make importance relative to the max importance\n",
        "feature_importance = 100.0 * (importances / importances.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "feature_names = list(df_X_train.columns.values)\n",
        "feature_names_sort = [feature_names[indice] for indice in sorted_idx]\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "# plot the result\n",
        "fig = plt.figure(figsize=(9,8))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, feature_names_sort)\n",
        "plt.title('GRB Model: Relative Feature Importance', fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:44:21.507375Z",
          "iopub.execute_input": "2022-02-20T18:44:21.507769Z",
          "iopub.status.idle": "2022-02-20T18:44:21.802644Z",
          "shell.execute_reply.started": "2022-02-20T18:44:21.507721Z",
          "shell.execute_reply": "2022-02-20T18:44:21.801575Z"
        },
        "trusted": true,
        "id": "vW55O0WThhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variables important\n",
        "# Model - DT\n",
        "\n",
        "importances = ML_models['DT'].feature_importances_\n",
        "\n",
        "# make importance relative to the max importance\n",
        "feature_importance = 100.0 * (importances / importances.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "feature_names = list(df_X_train.columns.values)\n",
        "feature_names_sort = [feature_names[indice] for indice in sorted_idx]\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "# plot the result\n",
        "fig = plt.figure(figsize=(9,8))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, feature_names_sort)\n",
        "plt.title('DT Model: Relative Feature Importance', fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:44:21.804478Z",
          "iopub.execute_input": "2022-02-20T18:44:21.804819Z",
          "iopub.status.idle": "2022-02-20T18:44:22.105435Z",
          "shell.execute_reply.started": "2022-02-20T18:44:21.804772Z",
          "shell.execute_reply": "2022-02-20T18:44:22.104456Z"
        },
        "trusted": true,
        "id": "5jouXiqMhhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variables important\n",
        "# Model - XGB\n",
        "importances = ML_models['XGB'].feature_importances_\n",
        "\n",
        "# make importance relative to the max importance\n",
        "feature_importance = 100.0 * (importances / importances.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "feature_names = list(df_X_train.columns.values)\n",
        "feature_names_sort = [feature_names[indice] for indice in sorted_idx]\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "# plot the result\n",
        "fig = plt.figure(figsize=(9,8))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, feature_names_sort)\n",
        "plt.title('XGB Model: Relative Feature Importance', fontsize=12)\n",
        "plt.tick_params(labelsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:44:22.106792Z",
          "iopub.execute_input": "2022-02-20T18:44:22.107045Z",
          "iopub.status.idle": "2022-02-20T18:44:22.401129Z",
          "shell.execute_reply.started": "2022-02-20T18:44:22.107013Z",
          "shell.execute_reply": "2022-02-20T18:44:22.399972Z"
        },
        "trusted": true,
        "id": "lpvhRn6ihhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " RF model permutation_importances\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from rfpimp import permutation_importances\n",
        "\n",
        "def r2(model, X_train, y_train):\n",
        "    return r2_score(y_train, model.predict(X_train))\n",
        "\n",
        "perm_imp_rfpimp = permutation_importances(ML_models['RF'], df_X_train, y_train, r2).reset_index()\n",
        "\n",
        " plot the result\n",
        "fig = plt.figure(figsize=(9,8))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "g=sns.barplot(data=perm_imp_rfpimp, y=\"Feature\", x=\"Importance\")\n",
        "plt.title('Permutation_importances', fontsize=12)\n",
        "g.grid(False)\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNXWOD2lhhYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB Model\n",
        "df_X_t =pd.DataFrame(X_test)\n",
        "df_X_test=df_X_t.rename(columns={0:'V1', 1:'V2', 2:'V3', 3: 'V4', 4: 'V5', 5: 'V6', 6: 'V7', 7: 'V8',\n",
        "                              8: 'V9', 9: 'V10', 10: 'V11', 11: 'V12', 12: 'V13', 13: 'V14', 14: 'V15',15: 'V16',\n",
        "                              16:'V17', 17: 'V18', 18: 'V19', 19: 'V20', 20: 'V21', 21: 'V22',22: 'V23', 23: 'V24',\n",
        "                              24 :'V25', 25: 'V26', 26: 'V27', 27: 'V28', 28:'Amount'})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:49:18.312975Z",
          "iopub.execute_input": "2022-02-20T18:49:18.313481Z",
          "iopub.status.idle": "2022-02-20T18:49:18.356708Z",
          "shell.execute_reply.started": "2022-02-20T18:49:18.31343Z",
          "shell.execute_reply": "2022-02-20T18:49:18.355656Z"
        },
        "trusted": true,
        "id": "ztC4P8M9hhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cutoff - target for each model on probability\n",
        "\n",
        "# LR Model\n",
        "LR_y_pred_test = ML_models['LR'].predict_proba(X_test)\n",
        "LR_y_pred_df = pd.DataFrame(LR_y_pred_test)\n",
        "LR_y_pred = LR_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =LR_y_pred.index\n",
        "LR_y_pred_final = pd.concat([y_test,LR_y_pred],axis=1)\n",
        "\n",
        "LR_y_pred_final= LR_y_pred_final.rename(columns={ 1 : 'LR_Fraudulent_prob'})\n",
        "\n",
        "# RF Model\n",
        "RF_y_pred_test = ML_models['RF'].predict_proba(X_test)\n",
        "RF_y_pred_df = pd.DataFrame(RF_y_pred_test)\n",
        "RF_y_pred = RF_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =RF_y_pred.index\n",
        "RF_y_pred_final = pd.concat([y_test,RF_y_pred],axis=1)\n",
        "\n",
        "RF_y_pred_final= RF_y_pred_final.rename(columns={ 1 : 'RF_Fraudulent_prob'})\n",
        "\n",
        "# NN Model\n",
        "NN_y_pred_test = ML_models['NN'].predict_proba(X_test)\n",
        "NN_y_pred_df = pd.DataFrame(NN_y_pred_test)\n",
        "NN_y_pred = NN_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =NN_y_pred.index\n",
        "NN_y_pred_final = pd.concat([y_test,NN_y_pred],axis=1)\n",
        "\n",
        "NN_y_pred_final= NN_y_pred_final.rename(columns={ 1 : 'NN_Fraudulent_prob'})\n",
        "\n",
        "# GRB Model\n",
        "GRB_y_pred_test = ML_models['GRB'].predict_proba(X_test)\n",
        "GRB_y_pred_df = pd.DataFrame(GRB_y_pred_test)\n",
        "GRB_y_pred = GRB_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =GRB_y_pred.index\n",
        "GRB_y_pred_final = pd.concat([y_test,GRB_y_pred],axis=1)\n",
        "\n",
        "GRB_y_pred_final= GRB_y_pred_final.rename(columns={ 1 : 'GRB_Fraudulent_prob'})\n",
        "\n",
        "# DT Model\n",
        "\n",
        "DT_y_pred_test = ML_models['DT'].predict_proba(X_test)\n",
        "DT_y_pred_df = pd.DataFrame(DT_y_pred_test)\n",
        "DT_y_pred = DT_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =DT_y_pred.index\n",
        "DT_y_pred_final = pd.concat([y_test,DT_y_pred],axis=1)\n",
        "\n",
        "DT_y_pred_final= DT_y_pred_final.rename(columns={ 1 : 'DT_Fraudulent_prob'})\n",
        "\n",
        "# KN Model\n",
        "KN_y_pred_test = ML_models['KN'].predict_proba(X_test)\n",
        "KN_y_pred_df = pd.DataFrame(KN_y_pred_test)\n",
        "KN_y_pred = KN_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =KN_y_pred.index\n",
        "KN_y_pred_final = pd.concat([y_test,KN_y_pred],axis=1)\n",
        "\n",
        "KN_y_pred_final= KN_y_pred_final.rename(columns={ 1 : 'KN_Fraudulent_prob'})\n",
        "\n",
        "\n",
        "XGB_y_pred_test = ML_models['XGB'].predict_proba(X_test)\n",
        "XGB_y_pred_df = pd.DataFrame(XGB_y_pred_test)\n",
        "XGB_y_pred = XGB_y_pred_df.iloc[:,[1]]\n",
        "\n",
        "y_test.index =XGB_y_pred.index\n",
        "XGB_y_pred_final = pd.concat([y_test,XGB_y_pred],axis=1)\n",
        "\n",
        "XGB_y_pred_final= XGB_y_pred_final.rename(columns={ 1 : 'XGB_Fraudulent_prob'})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:49:23.989668Z",
          "iopub.execute_input": "2022-02-20T18:49:23.990424Z",
          "iopub.status.idle": "2022-02-20T18:57:54.08953Z",
          "shell.execute_reply.started": "2022-02-20T18:49:23.990369Z",
          "shell.execute_reply": "2022-02-20T18:57:54.088713Z"
        },
        "trusted": true,
        "id": "w08Ug3-6hhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create columns with different probability cutoffs\n",
        "# LR Model\n",
        "numbers = [float(x)/10 for x in range(10)]\n",
        "for i in numbers:\n",
        "     LR_y_pred_final[i]= LR_y_pred_final.LR_Fraudulent_prob.map(lambda x: 1 if x > i else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"LR Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(LR_y_pred_final.head()); Line_Separator1()\n",
        "\n",
        "# RF Model\n",
        "for j in numbers:\n",
        "     RF_y_pred_final[j]= RF_y_pred_final.RF_Fraudulent_prob.map(lambda x: 1 if x > j else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"RF Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(RF_y_pred_final.head()); Line_Separator1()\n",
        "\n",
        "\n",
        "# NN Model\n",
        "for k in numbers:\n",
        "     NN_y_pred_final[k]= NN_y_pred_final.NN_Fraudulent_prob.map(lambda x: 1 if x > k else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"NN Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(NN_y_pred_final.head()); Line_Separator1()\n",
        "\n",
        "# GRB Model\n",
        "for l in numbers:\n",
        "     GRB_y_pred_final[l]= GRB_y_pred_final.GRB_Fraudulent_prob.map(lambda x: 1 if x > l else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"GRB Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(GRB_y_pred_final.head());Line_Separator1()\n",
        "\n",
        "# DT Model\n",
        "for m in numbers:\n",
        "     DT_y_pred_final[m]= DT_y_pred_final.DT_Fraudulent_prob.map(lambda x: 1 if x > m else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"DT Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(DT_y_pred_final.head());Line_Separator1()\n",
        "\n",
        "#KN Model\n",
        "for n in numbers:\n",
        "     KN_y_pred_final[n]= KN_y_pred_final.KN_Fraudulent_prob.map(lambda x: 1 if x > n else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"KN Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(KN_y_pred_final.head());Line_Separator1()\n",
        "\n",
        "# XGB Model\n",
        "for o in numbers:\n",
        "     XGB_y_pred_final[o]= XGB_y_pred_final.XGB_Fraudulent_prob.map(lambda x: 1 if x > o else 0)\n",
        "print(); Line_Separator1()\n",
        "print (\"XGB Model -create columns with different probability cutoffs\"); Line_Separator1()\n",
        "print(XGB_y_pred_final.head());Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:57:54.094835Z",
          "iopub.execute_input": "2022-02-20T18:57:54.097034Z",
          "iopub.status.idle": "2022-02-20T18:57:57.987312Z",
          "shell.execute_reply.started": "2022-02-20T18:57:54.096984Z",
          "shell.execute_reply": "2022-02-20T18:57:57.98633Z"
        },
        "trusted": true,
        "id": "YpIh_cPYhhYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's calculate accuracy , sensitivity, and specificity for various probability cutoffs.\n",
        "\n",
        "# LR model\n",
        "print(); Line_Separator1()\n",
        "print (\"LR Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "LR_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(LR_y_pred_final.Class, LR_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    LR_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(LR_cutoff_df); Line_Separator1()\n",
        "\n",
        "\n",
        "# RF model\n",
        "print(); Line_Separator1()\n",
        "print (\"RF Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "RF_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(RF_y_pred_final.Class, RF_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    RF_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(RF_cutoff_df); Line_Separator1()\n",
        "\n",
        "\n",
        "# NN model\n",
        "print(); Line_Separator1()\n",
        "print (\"NN Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "NN_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(NN_y_pred_final.Class, NN_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    NN_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(NN_cutoff_df); Line_Separator1()\n",
        "\n",
        "\n",
        "# GRB model\n",
        "print(); Line_Separator1()\n",
        "print (\"GRB Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "GRB_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(GRB_y_pred_final.Class, GRB_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    GRB_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(GRB_cutoff_df); Line_Separator1()\n",
        "\n",
        "\n",
        "# DT model\n",
        "print(); Line_Separator1()\n",
        "print (\"DT Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "DT_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(DT_y_pred_final.Class, DT_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    DT_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(DT_cutoff_df); Line_Separator1()\n",
        "\n",
        "# KN model\n",
        "print(); Line_Separator1()\n",
        "print (\"DT Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "KN_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(KN_y_pred_final.Class, KN_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    KN_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(KN_cutoff_df); Line_Separator1()\n",
        "\n",
        "# XGB model\n",
        "print(); Line_Separator1()\n",
        "print (\"XGB Model -prob, accuracy, sensi, speci\"); Line_Separator1()\n",
        "XGB_cutoff_df = pd.DataFrame(columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(XGB_y_pred_final.Class, XGB_y_pred_final[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    sensi = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    speci = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    XGB_cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(XGB_cutoff_df); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:57:57.988758Z",
          "iopub.execute_input": "2022-02-20T18:57:57.98901Z",
          "iopub.status.idle": "2022-02-20T18:58:04.629594Z",
          "shell.execute_reply.started": "2022-02-20T18:57:57.98898Z",
          "shell.execute_reply": "2022-02-20T18:58:04.628341Z"
        },
        "trusted": true,
        "id": "vilb6H7YhhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Finding the optimal cutoff threshold\n",
        "def Find_Optimal_Cutoff(target, predicted):\n",
        "\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    i = np.arange(len(tpr))\n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
        "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "    return list(roc_t['threshold'])\n",
        "\n",
        "# Find optimal probability threshold\n",
        "LR_threshold = Find_Optimal_Cutoff(LR_y_pred_final.Class,LR_y_pred_final.LR_Fraudulent_prob)\n",
        "RF_threshold = Find_Optimal_Cutoff(RF_y_pred_final.Class,RF_y_pred_final.RF_Fraudulent_prob)\n",
        "NN_threshold = Find_Optimal_Cutoff(NN_y_pred_final.Class,NN_y_pred_final.NN_Fraudulent_prob)\n",
        "GRB_threshold = Find_Optimal_Cutoff(GRB_y_pred_final.Class,GRB_y_pred_final.GRB_Fraudulent_prob)\n",
        "DT_threshold = Find_Optimal_Cutoff(DT_y_pred_final.Class,DT_y_pred_final.DT_Fraudulent_prob)\n",
        "KN_threshold = Find_Optimal_Cutoff(KN_y_pred_final.Class,KN_y_pred_final.KN_Fraudulent_prob)\n",
        "XGB_threshold = Find_Optimal_Cutoff(XGB_y_pred_final.Class,XGB_y_pred_final.XGB_Fraudulent_prob)\n",
        "\n",
        "print(); Line_Separator1()\n",
        "print (\"ML_Models: Optimal Cutoff Threshold\"); Line_Separator1()\n",
        "\n",
        "print('LR Model Cutoff threshold: ', LR_threshold)\n",
        "print('RF Model Cutoff threshold: ', RF_threshold)\n",
        "print('NN Model Cutoff threshold: ', NN_threshold)\n",
        "print('GRB Model Cutoff threshold: ', GRB_threshold)\n",
        "print('DT Model Cutoff threshold: ', DT_threshold)\n",
        "print('KN Model Cutoff threshold: ', KN_threshold)\n",
        "print('XGB Model Cutoff threshold: ', XGB_threshold); Line_Separator1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:58:04.631722Z",
          "iopub.execute_input": "2022-02-20T18:58:04.63196Z",
          "iopub.status.idle": "2022-02-20T18:58:04.763206Z",
          "shell.execute_reply.started": "2022-02-20T18:58:04.631932Z",
          "shell.execute_reply": "2022-02-20T18:58:04.762317Z"
        },
        "trusted": true,
        "id": "Je2U6A6RhhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new column 'predicted' with 1 if Fraudulent > optimal cutoff threshold of each model else 0\n",
        "# LR model\n",
        "LR_y_pred_final['pred_Fraudulent'] = LR_y_pred_final.LR_Fraudulent_prob.map(lambda x: 1 if x > 0.6420354633413775 else 0)\n",
        "print(); Line_Separator()\n",
        "print('LR_Model');Line_Separator()\n",
        "print (LR_y_pred_final.Class.value_counts())\n",
        "\n",
        "# RF Model\n",
        "RF_y_pred_final['pred_Fraudulent'] = RF_y_pred_final.RF_Fraudulent_prob.map(lambda x: 1 if x >0.016428571428571428 else 0)\n",
        "print(); Line_Separator()\n",
        "print('RF_Model');Line_Separator()\n",
        "print (RF_y_pred_final.Class.value_counts())\n",
        "\n",
        "# NN Model\n",
        "NN_y_pred_final['pred_Fraudulent'] = NN_y_pred_final.NN_Fraudulent_prob.map(lambda x: 1 if x >0.00000000005824619724 else 0)\n",
        "print(); Line_Separator()\n",
        "print('NN_Model');Line_Separator()\n",
        "print (NN_y_pred_final.Class.value_counts())\n",
        "\n",
        "# GRB Model\n",
        "GRB_y_pred_final['pred_Fraudulent'] = GRB_y_pred_final.GRB_Fraudulent_prob.map(lambda x: 1 if x >0.4782707970396372 else 0)\n",
        "print(); Line_Separator()\n",
        "print('GRB_Model');Line_Separator()\n",
        "print (GRB_y_pred_final.Class.value_counts())\n",
        "\n",
        "# DT Model\n",
        "DT_y_pred_final['pred_Fraudulent'] = DT_y_pred_final.DT_Fraudulent_prob.map(lambda x: 1 if x >0.6093012806110987 else 0)\n",
        "print(); Line_Separator()\n",
        "print('DT_Model');Line_Separator()\n",
        "print(DT_y_pred_final.Class.value_counts())\n",
        "\n",
        "# KN Model\n",
        "KN_y_pred_final['pred_Fraudulent'] = KN_y_pred_final.KN_Fraudulent_prob.map(lambda x: 1 if x > 0.14285714285714285 else 0)\n",
        "print();Line_Separator()\n",
        "print('KN_Model');Line_Separator()\n",
        "print (KN_y_pred_final.Class.value_counts())\n",
        "\n",
        "# XGB Model\n",
        "\n",
        "XGB_y_pred_final['pred_Fraudulent'] = XGB_y_pred_final.XGB_Fraudulent_prob.map(lambda x: 1 if x >0.07481219619512558 else 0)\n",
        "print();Line_Separator()\n",
        "print('XGB_Model');Line_Separator()\n",
        "print (XGB_y_pred_final.Class.value_counts());Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:58:04.764924Z",
          "iopub.execute_input": "2022-02-20T18:58:04.76516Z",
          "iopub.status.idle": "2022-02-20T18:58:05.19721Z",
          "shell.execute_reply.started": "2022-02-20T18:58:04.765132Z",
          "shell.execute_reply": "2022-02-20T18:58:05.196265Z"
        },
        "trusted": true,
        "id": "GYk3YSnhhhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for LR, RF, NN, GRB, DT, KN, XGB models after incorporating cutoff traget value of each model\n",
        "\n",
        "# LR\n",
        "LR_conf_matrix = metrics.confusion_matrix(LR_y_pred_final.Class, LR_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# RF\n",
        "RF_conf_matrix = metrics.confusion_matrix(RF_y_pred_final.Class, RF_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# NN\n",
        "NN_conf_matrix = metrics.confusion_matrix(NN_y_pred_final.Class, NN_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# GRB\n",
        "GRB_conf_matrix = metrics.confusion_matrix(GRB_y_pred_final.Class, GRB_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# DT\n",
        "DT_conf_matrix = metrics.confusion_matrix(DT_y_pred_final.Class, DT_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# KN\n",
        "KN_conf_matrix = metrics.confusion_matrix(KN_y_pred_final.Class, KN_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "# XGB\n",
        "XGB_conf_matrix = metrics.confusion_matrix(XGB_y_pred_final.Class, XGB_y_pred_final.pred_Fraudulent)\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15,18))\n",
        "fig.set_facecolor(\"#F3F3F3\")\n",
        "plt.subplot(431)\n",
        "ax= sns.heatmap(LR_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"LR_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(432)\n",
        "ax= sns.heatmap(RF_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"RF_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(433)\n",
        "ax= sns.heatmap(NN_conf_matrix,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"NN_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(434)\n",
        "ax= sns.heatmap(GRB_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"GRB_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(435)\n",
        "ax= sns.heatmap(DT_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"DT_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.subplot(436)\n",
        "ax= sns.heatmap(KN_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"KN_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "\n",
        "plt.subplot(437)\n",
        "ax= sns.heatmap(XGB_conf_matrix ,annot=True, annot_kws={\"fontsize\":15}, fmt = \"\",square = True,\n",
        "                xticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                yticklabels=[\"Not Fraudulent\",\"Fraudulent\"],\n",
        "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
        "plt.title(\"XGB_conf_matrix\", fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=90, horizontalalignment='right')\n",
        "#bottom, top = ax.get_ylim()\n",
        "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:58:05.199119Z",
          "iopub.execute_input": "2022-02-20T18:58:05.199402Z",
          "iopub.status.idle": "2022-02-20T18:58:07.508425Z",
          "shell.execute_reply.started": "2022-02-20T18:58:05.199369Z",
          "shell.execute_reply": "2022-02-20T18:58:07.507473Z"
        },
        "trusted": true,
        "id": "DJNw6X0MhhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for LR, RF, NN, GRB, DT, KN, XGB models after incorporating cutoff target value of each model\n",
        "\n",
        "# LR model\n",
        "\n",
        "TP_LR = LR_conf_matrix[1,1] # true positive\n",
        "TN_LR = LR_conf_matrix[0,0] # true negatives\n",
        "FP_LR = LR_conf_matrix[0,1] # false positives\n",
        "FN_LR = LR_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# RF model\n",
        "\n",
        "TP_RF = RF_conf_matrix[1,1] # true positive\n",
        "TN_RF = RF_conf_matrix[0,0] # true negatives\n",
        "FP_RF = RF_conf_matrix[0,1] # false positives\n",
        "FN_RF = RF_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# NN model\n",
        "\n",
        "TP_NN = NN_conf_matrix[1,1] # true positive\n",
        "TN_NN = NN_conf_matrix[0,0] # true negatives\n",
        "FP_NN = NN_conf_matrix[0,1] # false positives\n",
        "FN_NN = NN_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# GRB model\n",
        "\n",
        "TP_GRB = GRB_conf_matrix[1,1] # true positive\n",
        "TN_GRB = GRB_conf_matrix[0,0] # true negatives\n",
        "FP_GRB = GRB_conf_matrix[0,1] # false positives\n",
        "FN_GRB = GRB_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# DT model\n",
        "\n",
        "TP_DT = DT_conf_matrix[1,1] # true positive\n",
        "TN_DT = DT_conf_matrix[0,0] # true negatives\n",
        "FP_DT = DT_conf_matrix[0,1] # false positives\n",
        "FN_DT = DT_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# KN model\n",
        "\n",
        "TP_KN = KN_conf_matrix[1,1] # true positive\n",
        "TN_KN = KN_conf_matrix[0,0] # true negatives\n",
        "FP_KN = KN_conf_matrix[0,1] # false positives\n",
        "FN_KN = KN_conf_matrix[1,0] # false negatives\n",
        "\n",
        "# XGB  model\n",
        "\n",
        "TP_XGB = XGB_conf_matrix[1,1] # true positive\n",
        "TN_XGB = XGB_conf_matrix[0,0] # true negatives\n",
        "FP_XGB = XGB_conf_matrix[0,1] # false positives\n",
        "FN_XGB = XGB_conf_matrix[1,0] # false negatives"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:58:07.511189Z",
          "iopub.execute_input": "2022-02-20T18:58:07.511574Z",
          "iopub.status.idle": "2022-02-20T18:58:07.525575Z",
          "shell.execute_reply.started": "2022-02-20T18:58:07.511524Z",
          "shell.execute_reply": "2022-02-20T18:58:07.524573Z"
        },
        "trusted": true,
        "id": "ehiVl5MThhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print();Line_Separator()\n",
        "\n",
        "# LR model statistics-----------------------------------------------------------\n",
        "print(\"LR Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity / Recall      : ', TP_LR / float(TP_LR+FN_LR))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity / Precision   : ',TN_LR / float(TN_LR+FP_LR))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_LR/ float(TN_LR+FP_LR))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_LR / float(TP_LR+FP_LR))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ', TN_LR / float(TN_LR+ FN_LR))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "LR_Precision  = TP_LR/float(TP_LR + FP_LR)\n",
        "LR_recall     = TP_LR/float(TP_LR + FN_LR)\n",
        "LR_F1_Score      = 2*((LR_Precision*LR_recall)/(LR_Precision+LR_recall))\n",
        "print ('F1 Score                  : ',  LR_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "LR_Accuracy  = (TP_LR + TN_LR)/ float(TP_LR+TN_LR+FP_LR+FN_LR)\n",
        "print ('Accuracy                  : ',  LR_Accuracy);Line_Separator()\n",
        "\n",
        "\n",
        "\n",
        "# RF model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"RF Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_RF / float(TP_RF+FN_RF))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_RF / float(TN_RF+FP_RF))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_RF/ float(TN_RF+FP_RF))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_RF / float(TP_RF+FP_RF))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',TN_RF / float(TN_RF+ FN_RF))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "RF_Precision  = TP_RF/float(TP_RF + FP_RF)\n",
        "RF_recall     = TP_LR/float(TP_RF + FN_RF)\n",
        "RF_F1_Score      = 2*((RF_Precision*RF_recall)/(RF_Precision+RF_recall))\n",
        "print ('F1 Score                  : ',  RF_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "RF_Accuracy  = (TP_RF + TN_RF)/ float(TP_RF+TN_RF+FP_RF+FN_RF)\n",
        "print ('Accuracy                  : ',  RF_Accuracy);Line_Separator()\n",
        "\n",
        "\n",
        "# NN model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"NN Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_NN / float(TP_NN+FN_NN))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_NN / float(TN_NN+FP_NN))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_NN/ float(TN_NN+FP_NN))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_NN / float(TP_NN+FP_NN))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ', TN_NN / float(TN_NN+ FN_NN))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "NN_Precision  = TP_NN/float(TP_NN + FP_NN)\n",
        "NN_recall     = TP_NN/float(TP_NN + FN_NN)\n",
        "NN_F1_Score      = 2*((NN_Precision*NN_recall)/(NN_Precision+NN_recall))\n",
        "print ('F1 Score                  : ',  NN_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "NN_Accuracy  = (TP_NN + TN_NN)/ float(TP_NN+TN_NN+FP_NN+FN_NN)\n",
        "print ('Accuracy                  : ',  NN_Accuracy);Line_Separator()\n",
        "\n",
        "# GRB model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"GRB Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_GRB / float(TP_GRB+FN_GRB))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_GRB / float(TN_GRB+FP_GRB))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_GRB/ float(TN_GRB+FP_GRB))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_GRB / float(TP_GRB+FP_GRB))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ', TN_GRB / float(TN_GRB+ FN_GRB))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "GRB_Precision  = TP_GRB/float(TP_GRB + FP_GRB)\n",
        "GRB_recall     = TP_GRB/float(TP_GRB + FN_GRB)\n",
        "GRB_F1_Score      = 2*((GRB_Precision*GRB_recall)/(GRB_Precision+GRB_recall))\n",
        "print ('F1 Score                  : ',  GRB_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "GRB_Accuracy  = (TP_GRB + TN_GRB)/ float(TP_GRB+TN_GRB+FP_GRB+FN_GRB)\n",
        "print ('Accuracy                  : ',  GRB_Accuracy);Line_Separator()\n",
        "\n",
        "# DT model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"DT Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_DT / float(TP_DT+FN_DT))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_DT / float(TN_DT+FP_DT))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_DT/ float(TN_DT+FP_DT))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_DT / float(TP_DT+FP_DT))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ', TN_DT / float(TN_DT+ FN_DT))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "DT_Precision  = TP_DT/float(TP_DT + FP_DT)\n",
        "DT_recall     = TP_DT/float(TP_DT + FN_DT)\n",
        "DT_F1_Score      = 2*((DT_Precision*DT_recall)/(DT_Precision+DT_recall))\n",
        "print ('F1 Score                  : ',  DT_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "DT_Accuracy  = (TP_DT + TN_DT)/ float(TP_DT+TN_DT+FP_DT+FN_DT)\n",
        "print ('Accuracy                  : ',  DT_Accuracy);Line_Separator()\n",
        "\n",
        "# KN model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"KN Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_KN / float(TP_KN+FN_KN))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_KN / float(TN_KN+FP_KN))\n",
        "\n",
        "# Calculate false postive rate - predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_KN/ float(TN_KN+FP_KN))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_KN / float(TP_KN+FP_KN))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',TN_KN / float(TN_KN+ FN_KN))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "KN_Precision  = TP_KN/float(TP_KN + FP_KN)\n",
        "KN_recall     = TP_KN/float(TP_KN + FN_KN)\n",
        "KN_F1_Score      = 2*((KN_Precision*KN_recall)/(KN_Precision+KN_recall))\n",
        "print ('F1 Score                  : ',  KN_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "KN_Accuracy  = (TP_KN + TN_KN)/ float(TP_KN+TN_KN+FP_KN+FN_KN)\n",
        "print ('Accuracy                  : ', KN_Accuracy);Line_Separator()\n",
        "\n",
        "# XGB model statistics -------------------------------------------------------------\n",
        "\n",
        "print(\"XGB Model :\");Line_Separator()\n",
        "\n",
        "# Let's see the sensitivity of our logistic regression model\n",
        "print('Sensitivity               : ', TP_XGB / float(TP_XGB+FN_XGB))\n",
        "\n",
        "# Let us calculate specificity\n",
        "print('Specificity               : ',TN_XGB / float(TN_XGB+FP_XGB))\n",
        "\n",
        "# Calculate false postive rate -predicting Fraudulent when does not have Fraudulent\n",
        "print('False postive rate        : ',FP_XGB/ float(TN_XGB+FP_XGB))\n",
        "\n",
        "# positive predictive value\n",
        "print('Positive predictive value : ', TP_XGB / float(TP_XGB+FP_XGB))\n",
        "\n",
        "# Negative predictive value\n",
        "print('Negative predictive value : ',TN_XGB / float(TN_XGB+ FN_XGB))\n",
        "\n",
        "# F1 Score\n",
        "\n",
        "XGB_Precision  = TP_XGB/float(TP_XGB + FP_XGB)\n",
        "XGB_recall     = TP_XGB/float(TP_XGB + FN_XGB)\n",
        "XGB_F1_Score      = 2*((XGB_Precision*XGB_recall)/(XGB_Precision+XGB_recall))\n",
        "print ('F1 Score                  : ',  XGB_F1_Score)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "XGB_Accuracy  = (TP_XGB + TN_XGB)/ float(TP_XGB+TN_XGB+FP_XGB+FN_XGB)\n",
        "print ('Accuracy                  : ',  XGB_Accuracy);Line_Separator()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-20T18:58:07.527145Z",
          "iopub.execute_input": "2022-02-20T18:58:07.527485Z",
          "iopub.status.idle": "2022-02-20T18:58:07.586584Z",
          "shell.execute_reply.started": "2022-02-20T18:58:07.527449Z",
          "shell.execute_reply": "2022-02-20T18:58:07.5857Z"
        },
        "trusted": true,
        "id": "kE6FAeSuhhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION**\n",
        "\n",
        "1. We have created 5 Models and have evaluated all of these models based on different evaluation metrics for these models. The parameter area under the ROC curve plays an important role when we select the model in this study.\n",
        "\n",
        "2. Apart from Area under the ROC curve and precision/recall values, we have to consider the computation time when we think of any model here, as the amount of data we believe here is very high. Different models performed well on this data significant difference being the computation timing between these models. KNN model was not advisable as the information we have has more data points, more than 10k in it, which essentially increases the computational time of the model.\n",
        "\n",
        "3. Other metrics considered were Accuracy, Sensitivity/Recall, and Specificity/Precision. The selected model should strike the right balance between precision and recall. Identifying the fraud precisely is as important as reducing the misidentification of these transactions because both situations result in a loss for the client. So the model selected shall have the correct precision-recall with Area under the ROC curve. Model recommendations: 1) Based on the Area under the ROC curve, we can consider the logistic regression model with an l2 penalty can be used as the Area under the ROC curve is around 0.9862, which is the highest among all the other models. The Sensitivity/Recall for the LR model is 0.9387, and the Specificity/Precision stands at 0.9383, which are both quite good values. 2) Next model which is recommended is GRB Model. The Area under the ROC curve for this model is 0.977, which is an excellent value among other models. The Sensitivity/Recall for the LR model is 0.9183, and the Specificity/Precision is 0.9183 with an accuracy of .918, which is very well-balanced for our scenario.\n",
        "\n",
        "4. Other models, such as Random forest and XG boost, also have thriving areas under the ROC curve with values .975 and .966 and well-balanced precision/recall values and can be considered for evaluation."
      ],
      "metadata": {
        "id": "fZ6xmZYNhhYO"
      }
    }
  ]
}